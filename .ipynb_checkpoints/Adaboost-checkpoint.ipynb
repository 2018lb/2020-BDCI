{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_csv('attr.txt', sep='\\t',\n",
    "                           names=['link', 'length', 'direction', 'path_class', 'speed_class', 'LaneNum', 'speed_limit',\n",
    "                                  'level', 'width'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('is_train_2019070' + str(1) + '.txt')\n",
    "test = pd.read_csv('is_test.csv')\n",
    "train = train.merge(attr, on='link', how='left')\n",
    "test = test.merge(attr, on='link', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'link'\n",
    "use_train_feats = [i for i in train.columns if i not in ['link', 'label', 'current_slice_id', 'future_slice_id', 'label_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id = train[id_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= train.loc[:,use_train_feats]\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train['label'])\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_weakers_limit):\n",
    "        self.weights = []\n",
    "        self.classifiers = []\n",
    "        self.n_weakers_limit = n_weakers_limit\n",
    "        self.ws = []\n",
    "        pass\n",
    "\n",
    "    def is_good_enough(self,X_train,y_train):\n",
    "        if((len(self.classifiers) > self.n_weakers_limit) or\n",
    "                accuracy_score(y_train, self.predict(X_train))>=0.9):\n",
    "            return True\n",
    "        else:\n",
    "            #print(\"准确率：\" + str(accuracy_score(y_train, self.predict(X_train))))\n",
    "            print(classification_report(y_train, self.predict(X_train), digits=4))\n",
    "            report = f1_score(y_train, self.predict(X_train), average=None)\n",
    "            print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "            return False\n",
    "        pass\n",
    "\n",
    "    def fit(self,X_train,y_train):\n",
    "        w = np.ones((1, len(X_train))) / len(y_train)\n",
    "        flag = 0\n",
    "        while (flag == 0 or (not(self.is_good_enough(X_train,y_train)))):\n",
    "        #for i in range(2):\n",
    "            # 定义并训练基分类器决策树\n",
    "            flag = 1\n",
    "            clf = tree.DecisionTreeClassifier\\\n",
    "            (class_weight=\"balanced\", criterion='gini', max_depth=15, splitter=\"random\",random_state=0)\n",
    "            predit_tree = clf.fit(X_train, y_train, w.reshape(-1))\n",
    "            #predit_tree = clf.fit(X_train, y_train)\n",
    "            self.classifiers.append(predit_tree)\n",
    "            # 计算错误率\n",
    "            correct_rate = predit_tree.score(X_train, y_train)\n",
    "            error_rate = 1 - correct_rate\n",
    "            # 计算分类器权重\n",
    "            alpha = 1 / 2 * np.log((1 - error_rate) / error_rate)\n",
    "            # 存储分类器权重\n",
    "            self.weights.append(alpha)\n",
    "            # 计算预测结果\n",
    "            result = predit_tree.predict(X_train).reshape(-1, 1)\n",
    "            # 更新数据集权重参数\n",
    "            first_part = -alpha * y_train\n",
    "            second_part = np.exp(first_part * result)\n",
    "            third_part = (w.reshape(-1, 1) * second_part)\n",
    "            z_t = np.sum(third_part)\n",
    "            w = w.reshape(-1, 1) * second_part / z_t\n",
    "            self.ws.append(w)\n",
    "            print(alpha)\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_train, threshold=0):\n",
    "        scores = []\n",
    "        lenth = len(self.classifiers)\n",
    "        mmm_0 = np.zeros((len(X_train),1))\n",
    "        mmm_1 = np.zeros((len(X_train),1))\n",
    "        mmm_2 = np.zeros((len(X_train),1))\n",
    "        \n",
    "        for i in range(lenth):\n",
    "            kk = self.classifiers[i].predict(X_train).reshape(-1,1)\n",
    "            sum_0 = np.where(kk == 0, 1, 0)\n",
    "            sum_0 = sum_0.astype(np.float64)\n",
    "            sum_0 *= self.weights[i]\n",
    "            mmm_0 += sum_0\n",
    "            #print(mmm_0)\n",
    "            sum_1 = np.where(kk == 1, 1, 0)\n",
    "            sum_1 = sum_1.astype(np.float64)\n",
    "            sum_1 *= self.weights[i]\n",
    "            mmm_1 += sum_1\n",
    "\n",
    "            sum_2 = np.where(kk == 2, 1, 0)\n",
    "            sum_2 = sum_2.astype(np.float64)\n",
    "            sum_2 *= self.weights[i]\n",
    "            mmm_2 += sum_2\n",
    "\n",
    "        mmm = np.concatenate((mmm_0,mmm_1,mmm_2),axis=1)\n",
    "        return np.argmax(mmm,axis=1)     \n",
    "        pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save(model, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_weakers_limit):\n",
    "        self.weights = []\n",
    "        self.classifiers = []\n",
    "        self.n_weakers_limit = n_weakers_limit\n",
    "        self.ws = []\n",
    "        pass\n",
    "\n",
    "    def is_good_enough(self,X_ver,y_ver):\n",
    "        if((len(self.classifiers) > self.n_weakers_limit) or\n",
    "                accuracy_score(y_ver, self.predict(X_ver))>=0.9):\n",
    "            print(classification_report(y_ver, self.predict(X_ver), digits=4))\n",
    "            report = f1_score(y_ver, self.predict(X_ver), average=None)\n",
    "            print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "            return True\n",
    "        else:\n",
    "            print(classification_report(y_ver, self.predict(X_ver), digits=4))\n",
    "            report = f1_score(y_ver, self.predict(X_ver), average=None)\n",
    "            print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "            return False\n",
    "        pass\n",
    "\n",
    "    def fit(self,X_train,y_train,X_ver,y_ver):\n",
    "        w = np.ones((1, len(X_train))) / len(y_train)\n",
    "        flag = 0\n",
    "        while (flag == 0 or (not(self.is_good_enough(X_ver,y_ver)))):\n",
    "        #for i in range(2):\n",
    "            # 定义并训练基分类器决策树\n",
    "            flag = 1\n",
    "            clf = tree.DecisionTreeClassifier\\\n",
    "            (class_weight=\"balanced\", criterion='gini', max_depth=10, splitter=\"random\",random_state=0,min_weight_fraction_leaf=0.0001)\n",
    "            predit_tree = clf.fit(X_train, y_train, w.reshape(-1))\n",
    "            #predit_tree = clf.fit(X_train, y_train)\n",
    "            self.classifiers.append(predit_tree)\n",
    "            # 计算错误率\n",
    "            correct_rate = predit_tree.score(X_train, y_train)\n",
    "            error_rate = 1 - correct_rate\n",
    "            # 计算分类器权重\n",
    "            bbb = f1_score(y_ver, predit_tree.predict(X_ver), average=None)\n",
    "            alpha = bbb[0] * 0.2 + bbb[1] * 0.2 + bbb[2] * 0.6\n",
    "            #alpha = 1 / 2 * np.log((1 - error_rate) / error_rate)\n",
    "            # 存储分类器权重\n",
    "            self.weights.append(alpha)\n",
    "            # 计算预测结果\n",
    "            result = predit_tree.predict(X_train).reshape(-1, 1)\n",
    "            # 更新数据集权重参数\n",
    "            first_part = -alpha * y_train\n",
    "            second_part = np.exp(first_part * result)\n",
    "            third_part = (w.reshape(-1, 1) * second_part)\n",
    "            z_t = np.sum(third_part)\n",
    "            w = w.reshape(-1, 1) * second_part / z_t\n",
    "            self.ws.append(w)\n",
    "            #print(alpha)\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_train, threshold=0):\n",
    "        scores = []\n",
    "        lenth = len(self.classifiers)\n",
    "        mmm_0 = np.zeros((len(X_train),1))\n",
    "        mmm_1 = np.zeros((len(X_train),1))\n",
    "        mmm_2 = np.zeros((len(X_train),1))\n",
    "        \n",
    "        for i in range(lenth):\n",
    "            kk = self.classifiers[i].predict(X_train).reshape(-1,1)\n",
    "            sum_0 = np.where(kk == 0, 1, 0)\n",
    "            sum_0 = sum_0.astype(np.float64)\n",
    "            sum_0 *= self.weights[i]\n",
    "            mmm_0 += sum_0\n",
    "            #print(mmm_0)\n",
    "            sum_1 = np.where(kk == 1, 1, 0)\n",
    "            sum_1 = sum_1.astype(np.float64)\n",
    "            sum_1 *= self.weights[i]\n",
    "            mmm_1 += sum_1\n",
    "\n",
    "            sum_2 = np.where(kk == 2, 1, 0)\n",
    "            sum_2 = sum_2.astype(np.float64)\n",
    "            sum_2 *= self.weights[i]\n",
    "            mmm_2 += sum_2\n",
    "\n",
    "        mmm = np.concatenate((mmm_0,mmm_1,mmm_2),axis=1)\n",
    "        return np.argmax(mmm,axis=1)     \n",
    "        pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save(model, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = f1_score(y1, AdaBoostClassifiers.classifiers[0].predict(X_train1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86753025, 0.48751933, 0.40239376])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "7\n",
      "[0 1 0 1]\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[2, 4, 6, 1], [1, 5, 2, 9]])\n",
    "print(a.shape)\n",
    "print(np.argmax(a))\n",
    "print(np.argmax(a, axis=0))  #竖着比较，返回行号\n",
    "print(np.argmax(a, axis=1))  #横着比较，返回列号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifiers = AdaBoostClassifier(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.7950    0.8687    416466\n",
      "           1     0.3709    0.6194    0.4639     68946\n",
      "           2     0.2622    0.6165    0.3679     18144\n",
      "\n",
      "    accuracy                         0.7645    503556\n",
      "   macro avg     0.5302    0.6769    0.5669    503556\n",
      "weighted avg     0.8522    0.7645    0.7953    503556\n",
      "\n",
      "Score:  0.4873018365816424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9444    0.8513    0.8954    416466\n",
      "           1     0.4293    0.6523    0.5178     68946\n",
      "           2     0.3228    0.4158    0.3635     18144\n",
      "\n",
      "    accuracy                         0.8084    503556\n",
      "   macro avg     0.5655    0.6398    0.5922    503556\n",
      "weighted avg     0.8515    0.8084    0.8246    503556\n",
      "\n",
      "Score:  0.5007440600960844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9448    0.8648    0.9031    416466\n",
      "           1     0.4413    0.6642    0.5303     68946\n",
      "           2     0.3985    0.4083    0.4034     18144\n",
      "\n",
      "    accuracy                         0.8209    503556\n",
      "   macro avg     0.5949    0.6458    0.6122    503556\n",
      "weighted avg     0.8562    0.8209    0.8340    503556\n",
      "\n",
      "Score:  0.528690050626092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9413    0.8736    0.9062    416466\n",
      "           1     0.4489    0.6554    0.5328     68946\n",
      "           2     0.4445    0.4005    0.4213     18144\n",
      "\n",
      "    accuracy                         0.8267    503556\n",
      "   macro avg     0.6115    0.6432    0.6201    503556\n",
      "weighted avg     0.8559    0.8267    0.8376    503556\n",
      "\n",
      "Score:  0.5406133697938144\n"
     ]
    }
   ],
   "source": [
    "#AdaBoostClassifiers.fit(X_train,y,X_train1,y1)\n",
    "AdaBoostClassifiers.fit(X_train1,y1,X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9559    0.7695    0.8526    416466\n",
      "           1     0.3616    0.5647    0.4409     68946\n",
      "           2     0.2009    0.6710    0.3093     18144\n",
      "\n",
      "    accuracy                         0.7379    503556\n",
      "   macro avg     0.5061    0.6684    0.5343    503556\n",
      "weighted avg     0.8473    0.7379    0.7767    503556\n",
      "\n",
      "Score:  0.44425810939194155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.8633    0.8989    416466\n",
      "           1     0.4348    0.6069    0.5067     68946\n",
      "           2     0.3182    0.4173    0.3611     18144\n",
      "\n",
      "    accuracy                         0.8121    503556\n",
      "   macro avg     0.5635    0.6292    0.5889    503556\n",
      "weighted avg     0.8463    0.8121    0.8258    503556\n",
      "\n",
      "Score:  0.49776275497511613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9343    0.8852    0.9091    416466\n",
      "           1     0.4647    0.5957    0.5221     68946\n",
      "           2     0.3708    0.4204    0.3940     18144\n",
      "\n",
      "    accuracy                         0.8288    503556\n",
      "   macro avg     0.5899    0.6338    0.6084    503556\n",
      "weighted avg     0.8497    0.8288    0.8376    503556\n",
      "\n",
      "Score:  0.5226679462233922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9184    0.9256    0.9220    416466\n",
      "           1     0.4894    0.5463    0.5163     68946\n",
      "           2     0.3387    0.1279    0.1857     18144\n",
      "\n",
      "    accuracy                         0.8449    503556\n",
      "   macro avg     0.5822    0.5332    0.5413    503556\n",
      "weighted avg     0.8388    0.8449    0.8399    503556\n",
      "\n",
      "Score:  0.39903957127547696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9035    0.9408    0.9218    416466\n",
      "           1     0.5059    0.5070    0.5065     68946\n",
      "           2     0.3780    0.0166    0.0319     18144\n",
      "\n",
      "    accuracy                         0.8481    503556\n",
      "   macro avg     0.5958    0.4882    0.4867    503556\n",
      "weighted avg     0.8301    0.8481    0.8328    503556\n",
      "\n",
      "Score:  0.30477966349087854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8844    0.9704    0.9254    416466\n",
      "           1     0.5481    0.3681    0.4404     68946\n",
      "           2     0.4754    0.0074    0.0147     18144\n",
      "\n",
      "    accuracy                         0.8532    503556\n",
      "   macro avg     0.6359    0.4486    0.4601    503556\n",
      "weighted avg     0.8236    0.8532    0.8262    503556\n",
      "\n",
      "Score:  0.28194578129321013\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-86858340d18e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#AdaBoostClassifiers.fit(X_train,y,X_train1,y1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mAdaBoostClassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-116-ae4dbcdcae08>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, X_ver, y_ver)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"random\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mpredit_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[1;31m#predit_tree = clf.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredit_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#AdaBoostClassifiers.fit(X_train,y,X_train1,y1)\n",
    "AdaBoostClassifiers.fit(X_train1,y1,X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
       "                        max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.2, presort='deprecated',\n",
       "                        random_state=0, splitter='random'),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
       "                        max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.2, presort='deprecated',\n",
       "                        random_state=0, splitter='random'),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
       "                        max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.2, presort='deprecated',\n",
       "                        random_state=0, splitter='random'),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
       "                        max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.2, presort='deprecated',\n",
       "                        random_state=0, splitter='random')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoostClassifiers.classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('is_train_2019070' + str(2) + '.txt')\n",
    "train1 = train1.merge(attr, on='link', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(train1['label'])\n",
    "y1 = y1.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1= train1.loc[:,use_train_feats]\n",
    "X_train1 = np.array(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.90      0.91    415227\n",
      "           2       0.48      0.60      0.53     72621\n",
      "           3       0.47      0.22      0.30     18105\n",
      "\n",
      "    accuracy                           0.83    505953\n",
      "   macro avg       0.62      0.57      0.58    505953\n",
      "weighted avg       0.84      0.83      0.83    505953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1, AdaBoostClassifiers.predict(X_train1),target_names=['1','2','3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.46869645481451927\n"
     ]
    }
   ],
   "source": [
    "bbb = f1_score(y1, AdaBoostClassifiers.predict(X_train1), average=None)\n",
    "print('Score: ', bbb[0] * 0.2 + bbb[1] * 0.2 + bbb[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.89      0.90    415227\n",
      "           2       0.46      0.60      0.52     72621\n",
      "           3       0.36      0.25      0.29     18105\n",
      "\n",
      "    accuracy                           0.82    505953\n",
      "   macro avg       0.58      0.58      0.57    505953\n",
      "weighted avg       0.84      0.82      0.83    505953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1, AdaBoostClassifiers.classifiers[1].predict(X_train1),target_names=['1','2','3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.4606060580617193\n"
     ]
    }
   ],
   "source": [
    "bbb = f1_score(y1, AdaBoostClassifiers.classifiers[1].predict(X_train1), average=None)\n",
    "print('Score: ', bbb[0] * 0.2 + bbb[1] * 0.2 + bbb[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

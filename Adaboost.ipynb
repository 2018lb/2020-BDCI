{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_csv('attr.txt', sep='\\t',\n",
    "                           names=['link', 'length', 'direction', 'path_class', 'speed_class', 'LaneNum', 'speed_limit',\n",
    "                                  'level', 'width'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('is_train_2019070' + str(1) + '.txt')\n",
    "test = pd.read_csv('is_test.csv')\n",
    "train = train.merge(attr, on='link', how='left')\n",
    "test = test.merge(attr, on='link', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'link'\n",
    "use_train_feats = [i for i in train.columns if i not in ['link', 'label', 'current_slice_id', 'future_slice_id', 'label_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id = train[id_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= train.loc[:,use_train_feats]\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train['label'])\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_weakers_limit):\n",
    "        self.weights = []\n",
    "        self.classifiers = []\n",
    "        self.n_weakers_limit = n_weakers_limit\n",
    "        self.ws = []\n",
    "        pass\n",
    "\n",
    "    def is_good_enough(self,X_train,y_train):\n",
    "        if((len(self.classifiers) > self.n_weakers_limit) or\n",
    "                accuracy_score(y_train, self.predict(X_train))>=0.9):\n",
    "            return True\n",
    "        else:\n",
    "            #print(\"准确率：\" + str(accuracy_score(y_train, self.predict(X_train))))\n",
    "            print(classification_report(y_train, self.predict(X_train), digits=4))\n",
    "            report = f1_score(y_train, self.predict(X_train), average=None)\n",
    "            print('Score: ', report)\n",
    "            return False\n",
    "        pass\n",
    "\n",
    "    def fit(self,X_train,y_train):\n",
    "        w = np.ones((1, len(X_train))) / len(y_train)\n",
    "        flag = 0\n",
    "        while (flag == 0 or (not(self.is_good_enough(X_train,y_train)))):\n",
    "        #for i in range(2):\n",
    "            # 定义并训练基分类器决策树\n",
    "            flag = 1\n",
    "            clf = tree.DecisionTreeClassifier\\\n",
    "            (class_weight=\"balanced\", criterion='gini', max_depth=1, splitter=\"best\")\n",
    "            predit_tree = clf.fit(X_train, y_train, w.reshape(-1))\n",
    "            #predit_tree = clf.fit(X_train, y_train)\n",
    "            self.classifiers.append(predit_tree)\n",
    "            # 计算错误率\n",
    "            correct_rate = predit_tree.score(X_train, y_train)\n",
    "            error_rate = 1 - correct_rate\n",
    "            # 计算分类器权重\n",
    "            alpha = 1 / 2 * np.log((1 - error_rate) / error_rate)\n",
    "            # 存储分类器权重\n",
    "            self.weights.append(alpha)\n",
    "            # 计算预测结果\n",
    "            result = predit_tree.predict(X_train).reshape(-1, 1)\n",
    "            # 更新数据集权重参数\n",
    "            first_part = -alpha * y_train\n",
    "            second_part = np.exp(first_part * result)\n",
    "            third_part = (w.reshape(-1, 1) * second_part)\n",
    "            z_t = np.sum(third_part)\n",
    "            w = w.reshape(-1, 1) * second_part / z_t\n",
    "            self.ws.append(w)\n",
    "            print(alpha)\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_train, threshold=0):\n",
    "        scores = []\n",
    "        lenth = len(self.classifiers)\n",
    "        mmm_0 = np.zeros((len(X_train),1))\n",
    "        mmm_1 = np.zeros((len(X_train),1))\n",
    "        mmm_2 = np.zeros((len(X_train),1))\n",
    "        \n",
    "        for i in range(lenth):\n",
    "            kk = self.classifiers[i].predict(X_train).reshape(-1,1)\n",
    "            sum_0 = np.where(kk == 0, 1, 0)\n",
    "            sum_0 = sum_0.astype(np.float64)\n",
    "            sum_0 *= self.weights[i]\n",
    "            mmm_0 += sum_0\n",
    "            #print(mmm_0)\n",
    "            sum_1 = np.where(kk == 1, 1, 0)\n",
    "            sum_1 = sum_1.astype(np.float64)\n",
    "            sum_1 *= self.weights[i]\n",
    "            mmm_1 += sum_1\n",
    "\n",
    "            sum_2 = np.where(kk == 2, 1, 0)\n",
    "            sum_2 = sum_2.astype(np.float64)\n",
    "            sum_2 *= self.weights[i]\n",
    "            mmm_2 += sum_2\n",
    "\n",
    "        mmm = np.concatenate((mmm_0,mmm_1,mmm_2),axis=1)\n",
    "        return np.argmax(mmm,axis=1)     \n",
    "        pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save(model, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_weakers_limit):\n",
    "        self.weights = []\n",
    "        self.classifiers = []\n",
    "        self.n_weakers_limit = n_weakers_limit\n",
    "        self.ws = []\n",
    "        pass\n",
    "\n",
    "    def is_good_enough(self,X_ver,y_ver):\n",
    "        if((len(self.classifiers) > self.n_weakers_limit) or\n",
    "                accuracy_score(y_ver, self.predict(X_ver))>=0.9):\n",
    "            print(classification_report(y_ver, self.predict(X_ver), digits=4))\n",
    "            report = f1_score(y_ver, self.predict(X_ver), average=None)\n",
    "            print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "            return True\n",
    "        else:\n",
    "            print(classification_report(y_ver, self.predict(X_ver), digits=4))\n",
    "            report = f1_score(y_ver, self.predict(X_ver), average=None)\n",
    "            print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "            return False\n",
    "        pass\n",
    "\n",
    "    def fit(self,X_train,y_train,X_ver,y_ver):\n",
    "        w = np.ones((1, len(X_train))) / len(y_train)\n",
    "        flag = 0\n",
    "        while (flag == 0 or (not(self.is_good_enough(X_ver,y_ver)))):\n",
    "        #for i in range(2):\n",
    "            # 定义并训练基分类器决策树\n",
    "            flag = 1\n",
    "            clf = tree.DecisionTreeClassifier\\\n",
    "            (class_weight=\"balanced\", criterion='gini', max_depth=10, splitter=\"random\",random_state=0,min_weight_fraction_leaf=0.0001)\n",
    "            predit_tree = clf.fit(X_train, y_train, w.reshape(-1))\n",
    "            #predit_tree = clf.fit(X_train, y_train)\n",
    "            self.classifiers.append(predit_tree)\n",
    "            # 计算错误率\n",
    "            correct_rate = predit_tree.score(X_train, y_train)\n",
    "            error_rate = 1 - correct_rate\n",
    "            # 计算分类器权重\n",
    "            bbb = f1_score(y_ver, predit_tree.predict(X_ver), average=None)\n",
    "            alpha = bbb[0] * 0.2 + bbb[1] * 0.2 + bbb[2] * 0.6\n",
    "            #alpha = 1 / 2 * np.log((1 - error_rate) / error_rate)\n",
    "            # 存储分类器权重\n",
    "            self.weights.append(alpha)\n",
    "            # 计算预测结果\n",
    "            result = predit_tree.predict(X_train).reshape(-1, 1)\n",
    "            # 更新数据集权重参数\n",
    "            first_part = -alpha * y_train\n",
    "            second_part = np.exp(first_part * result)\n",
    "            third_part = (w.reshape(-1, 1) * second_part)\n",
    "            z_t = np.sum(third_part)\n",
    "            w = w.reshape(-1, 1) * second_part / z_t\n",
    "            self.ws.append(w)\n",
    "            #print(alpha)\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_train, threshold=0):\n",
    "        scores = []\n",
    "        lenth = len(self.classifiers)\n",
    "        mmm_0 = np.zeros((len(X_train),1))\n",
    "        mmm_1 = np.zeros((len(X_train),1))\n",
    "        mmm_2 = np.zeros((len(X_train),1))\n",
    "        \n",
    "        for i in range(lenth):\n",
    "            kk = self.classifiers[i].predict(X_train).reshape(-1,1)\n",
    "            sum_0 = np.where(kk == 0, 1, 0)\n",
    "            sum_0 = sum_0.astype(np.float64)\n",
    "            sum_0 *= self.weights[i]\n",
    "            mmm_0 += sum_0\n",
    "            #print(mmm_0)\n",
    "            sum_1 = np.where(kk == 1, 1, 0)\n",
    "            sum_1 = sum_1.astype(np.float64)\n",
    "            sum_1 *= self.weights[i]\n",
    "            mmm_1 += sum_1\n",
    "\n",
    "            sum_2 = np.where(kk == 2, 1, 0)\n",
    "            sum_2 = sum_2.astype(np.float64)\n",
    "            sum_2 *= self.weights[i]\n",
    "            mmm_2 += sum_2\n",
    "\n",
    "        mmm = np.concatenate((mmm_0,mmm_1,mmm_2),axis=1)\n",
    "        return np.argmax(mmm,axis=1)     \n",
    "        pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save(model, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = f1_score(y1, AdaBoostClassifiers.classifiers[0].predict(X_train1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[2, 4, 6, 1], [1, 5, 2, 9]])\n",
    "print(a.shape)\n",
    "print(np.argmax(a))\n",
    "print(np.argmax(a, axis=0))  #竖着比较，返回行号\n",
    "print(np.argmax(a, axis=1))  #横着比较，返回列号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifiers = AdaBoostClassifier(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AdaBoostClassifiers.fit(X_train,y,X_train1,y1)\n",
    "AdaBoostClassifiers.fit(X_train1,y1,X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AdaBoostClassifiers.fit(X_train,y,X_train1,y1)\n",
    "AdaBoostClassifiers.fit(X_train1,y1,X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifiers.classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('is_train_2019070' + str(2) + '.txt')\n",
    "train1 = train1.merge(attr, on='link', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(train1['label'])\n",
    "y1 = y1.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1= train1.loc[:,use_train_feats]\n",
    "X_train1 = np.array(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1, AdaBoostClassifiers.predict(X_train1),target_names=['1','2','3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = f1_score(y1, AdaBoostClassifiers.predict(X_train1), average=None)\n",
    "print('Score: ', bbb[0] * 0.2 + bbb[1] * 0.2 + bbb[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1, AdaBoostClassifiers.classifiers[1].predict(X_train1),target_names=['1','2','3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = f1_score(y1, AdaBoostClassifiers.classifiers[1].predict(X_train1), average=None)\n",
    "print('Score: ', bbb[0] * 0.2 + bbb[1] * 0.2 + bbb[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

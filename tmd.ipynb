{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import Layer, Input, Embedding, LSTM, Dense, Attention,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        # Encode LSTM Layer\n",
    "        self.encoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name=\"encode_lstm\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoder_embed = self.embedding(inputs)\n",
    "        encoder_outputs, state_h, state_c = self.encoder_lstm(encoder_embed)\n",
    "        return encoder_outputs, state_h, state_c\n",
    "        #return encoder_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        # Decode LSTM Layer\n",
    "        self.decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name=\"decode_lstm\")\n",
    "        # Attention Layer\n",
    "        self.attention = Attention()\n",
    "    \n",
    "    def call(self, enc_outputs, dec_inputs, states_inputs):\n",
    "    #def call(self, dec_inputs):\n",
    "        decoder_embed = self.embedding(dec_inputs)\n",
    "        dec_outputs, dec_state_h, dec_state_c = self.decoder_lstm(decoder_embed, initial_state=states_inputs)\n",
    "        #attention_output = self.attention([dec_outputs, enc_outputs])\n",
    "        return dec_outputs, dec_state_h, dec_state_c\n",
    "        #return attention_output, dec_state_h, dec_state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Seq2Seq(maxlen, embedding_dim, hidden_units, vocab_size):\n",
    "    \"\"\"\n",
    "    seq2seq model\n",
    "    \"\"\"\n",
    "    # Input Layer\n",
    "    encoder_inputs = Input(shape=(maxlen,), name=\"encode_input\")\n",
    "    decoder_inputs = Input(shape=(maxlen,), name=\"decode_input\")\n",
    "    # Encoder Layer\n",
    "    encoder = Encoder(vocab_size, embedding_dim, hidden_units)\n",
    "    enc_outputs, enc_state_h, enc_state_c = encoder(encoder_inputs)\n",
    "    dec_states_inputs = [enc_state_h, enc_state_c]\n",
    "    # Decoder Layer\n",
    "    decoder = Decoder(vocab_size, embedding_dim, hidden_units)\n",
    "    attention_output, dec_state_h, dec_state_c = decoder(enc_outputs, decoder_inputs, dec_states_inputs)\n",
    "    # Dense Layer\n",
    "    flatten_outputs = Flatten()(attention_output)\n",
    "    dense_outputs = Dense(vocab_size, activation='softmax', name=\"dense\")(flatten_outputs)\n",
    "    # seq2seq model\n",
    "    model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=dense_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 82\n",
    "embedding_dim = 50\n",
    "hidden_units = 128\n",
    "vocab_size = 3\n",
    "\n",
    "model = Seq2Seq(maxlen, embedding_dim, hidden_units, vocab_size)\n",
    "#model.build(input_shape=(10000))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train/is_train_20190730.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_cols = [i for i in train.columns if i not in ['link', 'label', 'current_slice_id', 'future_slice_id', 'label_pred']]\n",
    "use_cols = [i for i in data.columns if i not in ['link', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[use_cols]\n",
    "y_train = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train-X_train.min(axis=0))/(X_train.max(axis=0)-X_train.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(loss=loss_fn, optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight={0:0.2,1:0.2,2:0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train, X_train], y_train, class_weight = class_weight,validation_data=([X_ver, X_ver], y_ver),\n",
    "          batch_size=2048, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'tmd_.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = pd.read_csv('train/is_train_20190701.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ver = asd[use_cols]\n",
    "y_ver = asd['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ver = np.array(X_ver)\n",
    "y_ver = np.array(y_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ver = (X_ver-X_ver.min(axis=0))/(X_ver.max(axis=0)-X_ver.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict([X_ver[0].reshape(1,-1),X_ver[0].reshape(1,-1)])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict([X_ver[:10000],X_ver[:10000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_ver)):\n",
    "    res = model.predict([X_ver[i:i+1],X_ver[i:i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.argmax(res,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_ver[:10000], temp, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.4790+0.9342)*0.2+0.4895*0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_info(x):\n",
    "    return [i.split(':')[-1] for i in x.split(' ')]\n",
    "\n",
    "def get_speed(x):\n",
    "    return np.array([i.split(',')[0] for i in x], dtype='float16')\n",
    "\n",
    "def get_eta(x):\n",
    "    return np.array([i.split(',')[1] for i in x], dtype='float16')\n",
    "\n",
    "def get_state(x):\n",
    "    return [int(i.split(',')[2]) for i in x]\n",
    "\n",
    "def get_cnt(x):\n",
    "    return np.array([i.split(',')[3] for i in x], dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feats(path, mode='is_train'):\n",
    "    df = pd.read_csv(path, sep=';', header=None)\n",
    "    df['link'] = df[0].apply(lambda x: x.split(' ')[0])\n",
    "    if mode == 'is_train':\n",
    "        df['label'] = df[0].apply(lambda x: int(x.split(' ')[1]))\n",
    "        df['label'] = df['label'].apply(lambda x: 3 if x > 3 else x)\n",
    "        df['label'] -= 1\n",
    "        df['current_slice_id'] = df[0].apply(lambda x: int(x.split(' ')[2]))\n",
    "        df['future_slice_id'] = df[0].apply(lambda x: int(x.split(' ')[3]))\n",
    "    else:\n",
    "        df['label'] = -1\n",
    "        df['current_slice_id'] = df[0].apply(lambda x: int(x.split(' ')[2]))\n",
    "        df['future_slice_id'] = df[0].apply(lambda x: int(x.split(' ')[3]))\n",
    "\n",
    "    df['time_diff'] = df['future_slice_id'] - df['current_slice_id']\n",
    "\n",
    "    df['curr_state'] = df[1].apply(lambda x: x.split(' ')[-1].split(':')[-1])\n",
    "    df['curr_speed'] = df['curr_state'].apply(lambda x: x.split(',')[0])\n",
    "    df['curr_eta'] = df['curr_state'].apply(lambda x: x.split(',')[1])\n",
    "    df['curr_cnt'] = df['curr_state'].apply(lambda x: x.split(',')[3])\n",
    "    df['curr_state'] = df['curr_state'].apply(lambda x: x.split(',')[2])\n",
    "    del df[0]\n",
    "\n",
    "    for i in tqdm(range(1, 6)):\n",
    "        df['his_info'] = df[i].apply(get_base_info)\n",
    "        if i == 1:\n",
    "            flg = 'current'\n",
    "        else:\n",
    "            flg = f'his_{(6 - i) * 7}'\n",
    "        df['his_speed'] = df['his_info'].apply(get_speed)\n",
    "        df[f'{flg}_speed_min'] = df['his_speed'].apply(lambda x: x.min())\n",
    "        df[f'{flg}_speed_max'] = df['his_speed'].apply(lambda x: x.max())\n",
    "        df[f'{flg}_speed_mean'] = df['his_speed'].apply(lambda x: x.mean())\n",
    "        df[f'{flg}_speed_std'] = df['his_speed'].apply(lambda x: x.std())\n",
    "\n",
    "        df['his_eta'] = df['his_info'].apply(get_eta)\n",
    "        df[f'{flg}_eta_min'] = df['his_eta'].apply(lambda x: x.min())\n",
    "        df[f'{flg}_eta_max'] = df['his_eta'].apply(lambda x: x.max())\n",
    "        df[f'{flg}_eta_mean'] = df['his_eta'].apply(lambda x: x.mean())\n",
    "        df[f'{flg}_eta_std'] = df['his_eta'].apply(lambda x: x.std())\n",
    "\n",
    "        df['his_cnt'] = df['his_info'].apply(get_cnt)\n",
    "        df[f'{flg}_cnt_min'] = df['his_cnt'].apply(lambda x: x.min())\n",
    "        df[f'{flg}_cnt_max'] = df['his_cnt'].apply(lambda x: x.max())\n",
    "        df[f'{flg}_cnt_mean'] = df['his_cnt'].apply(lambda x: x.mean())\n",
    "        df[f'{flg}_cnt_std'] = df['his_cnt'].apply(lambda x: x.std())\n",
    "\n",
    "        df['his_state'] = df['his_info'].apply(get_state)\n",
    "        df[f'{flg}_state'] = df['his_state'].apply(lambda x: Counter(x).most_common()[0][0])\n",
    "        df.drop([i, 'his_info', 'his_speed', 'his_eta', 'his_cnt', 'his_state'], axis=1, inplace=True)\n",
    "    if mode == 'is_train':\n",
    "        df.to_csv(f\"{mode}_{path.split('/')[-1]}\", index=False)\n",
    "    else:\n",
    "        df.to_csv(f\"is_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_eval(preds, valid_df):\n",
    "    labels = valid_df.get_label()\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    scores = f1_score(y_true=labels, y_pred=preds, average=None)\n",
    "    scores = scores[0]*0.2+scores[1]*0.2+scores[2]*0.8\n",
    "    return 'f1_score', scores, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train(train_: pd.DataFrame, test_: pd.DataFrame, use_train_feats: list, id_col: str, label: str,\n",
    "              n_splits: int, split_rs: int, is_shuffle=True, use_cart=False, cate_cols=None) -> pd.DataFrame:\n",
    "    if not cate_cols:\n",
    "        cate_cols = []\n",
    "    print('data shape:\\ntrain--{}\\ntest--{}'.format(train_.shape, test_.shape))\n",
    "    print('Use {} features ...'.format(len(use_train_feats)))\n",
    "    print('Use lightgbm to train ...')\n",
    "    n_class = train_[label].nunique()\n",
    "    train_[f'{label}_pred'] = 0\n",
    "    test_pred = np.zeros((test_.shape[0], n_class))\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = use_train_feats\n",
    "\n",
    "    folds = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=split_rs)\n",
    "    train_user_id = train_[id_col].unique()\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'None',\n",
    "        'num_leaves': 31,\n",
    "        'num_class': n_class,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'seed': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction_seed': 7,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'nthread': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_user_id), start=1):\n",
    "        print('the {} training start ...'.format(n_fold))\n",
    "        train_x, train_y = train_.loc[train_[id_col].isin(train_user_id[train_idx]), use_train_feats], train_.loc[\n",
    "            train_[id_col].isin(train_user_id[train_idx]), label]\n",
    "        valid_x, valid_y = train_.loc[train_[id_col].isin(train_user_id[valid_idx]), use_train_feats], train_.loc[\n",
    "            train_[id_col].isin(train_user_id[valid_idx]), label]\n",
    "        print(f'for train user:{len(train_idx)}\\nfor valid user:{len(valid_idx)}')\n",
    "\n",
    "        if use_cart:\n",
    "            dtrain = lgb.Dataset(train_x, label=train_y, categorical_feature=cate_cols)\n",
    "            dvalid = lgb.Dataset(valid_x, label=valid_y, categorical_feature=cate_cols)\n",
    "        else:\n",
    "            dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "            dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dvalid],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=f1_score_eval\n",
    "        )\n",
    "        fold_importance_df[f'fold_{n_fold}_imp'] = clf.feature_importance(importance_type='gain')\n",
    "        train_.loc[train_[id_col].isin(train_user_id[valid_idx]), f'{label}_pred'] = np.argmax(\n",
    "            clf.predict(valid_x, num_iteration=clf.best_iteration), axis=1)\n",
    "        test_pred += clf.predict(test_[use_train_feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    report = f1_score(train_[label], train_[f'{label}_pred'], average=None)\n",
    "    print(classification_report(train_[label], train_[f'{label}_pred'], digits=4))\n",
    "    print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "    test_[f'{label}_pred'] = np.argmax(test_pred, axis=1)\n",
    "    test_[label] = np.argmax(test_pred, axis=1)+1\n",
    "    five_folds = [f'fold_{f}_imp' for f in range(1, n_splits + 1)]\n",
    "    fold_importance_df['avg_imp'] = fold_importance_df[five_folds].mean(axis=1)\n",
    "    fold_importance_df.sort_values(by='avg_imp', ascending=False, inplace=True)\n",
    "    print(fold_importance_df[['Feature', 'avg_imp']].head(20))\n",
    "    return test_[[id_col, 'current_slice_id', 'future_slice_id', label]],clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "def load(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_csv('attr.txt', sep='\\t',\n",
    "                           names=['link', 'length', 'direction', 'path_class', 'speed_class', 'LaneNum', 'speed_limit',\n",
    "                                  'level', 'width'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i in range(10,20):\n",
    "        train_path = './traffic/201907' + str(i) + '.txt'\n",
    "        test_path = 'test.txt'\n",
    "        gen_feats(train_path, mode='is_train')\n",
    "        gen_feats(test_path, mode='is_test')\n",
    "    \n",
    "        train = pd.read_csv('is_train_201907' + str(i) + '.txt')\n",
    "        test = pd.read_csv('is_test.csv')\n",
    "        train = train.merge(attr, on='link', how='left')\n",
    "        test = test.merge(attr, on='link', how='left')\n",
    "    \n",
    "        use_cols = [i for i in train.columns if i not in ['link', 'label', 'current_slice_id', 'future_slice_id', 'label_pred']]\n",
    "    \n",
    "        sub,clf = lgb_train(train, test, use_cols, 'link', 'label', 5, 2020)\n",
    "        save(clf,'model/'+ '201907' + str(i) + '.txt')\n",
    "        #sub.to_csv('public_baseline.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i in range(20,30):\n",
    "        train_path = './traffic/201907' + str(i) + '.txt'\n",
    "        test_path = 'test.txt'\n",
    "        gen_feats(train_path, mode='is_train')\n",
    "        gen_feats(test_path, mode='is_test')\n",
    "    \n",
    "        train = pd.read_csv('is_train_201907' + str(i) + '.txt')\n",
    "        test = pd.read_csv('is_test.csv')\n",
    "        train = train.merge(attr, on='link', how='left')\n",
    "        test = test.merge(attr, on='link', how='left')\n",
    "    \n",
    "        use_cols = [i for i in train.columns if i not in ['link', 'label', 'current_slice_id', 'future_slice_id', 'label_pred']]\n",
    "    \n",
    "        sub,clf = lgb_train(train, test, use_cols, 'link', 'label', 5, 2020)\n",
    "        save(clf,'model/'+ '201907' + str(i) + '.txt')\n",
    "        #sub.to_csv('public_baseline.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('is_test.csv')\n",
    "test = test.merge(attr, on='link', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for i in range(1,10):\n",
    "    path = 'model/2019070'+ str(i) +'.txt'\n",
    "    #print(path)\n",
    "    clf = load(path)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,31):\n",
    "    path = 'model/201907'+ str(i) +'.txt'\n",
    "    #print(path)\n",
    "    clf = load(path)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('is_train_201907' + str(11) + '.txt')\n",
    "train = train.merge(attr, on='link', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__ = train\n",
    "id_col = 'link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id = train__[id_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train__.loc[:,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train__.loc[:, use_train_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clfs[0].predict(train_x, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flag = 0\n",
    "for clf in clfs:\n",
    "    test_pred = clf.predict(train_x, num_iteration=clf.best_iteration)\n",
    "    #print(test_pred.shape)\n",
    "    if(flag==0):\n",
    "        sum_result = test_pred[np.newaxis,:]\n",
    "    else:\n",
    "        sum_result = np.vstack((sum_result,test_pred[np.newaxis,:]))\n",
    "    flag = flag + 1\n",
    "    #print(sum_result.shape)\n",
    "    print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_30 = np.average(sum_result,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = np.average(sum_result,axis=0)\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1[:,0] *= 0.8\n",
    "temp1[:,1] *= 0.8\n",
    "temp1[:,2] *= 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = np.argmax(temp1,axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = label1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.array(train_y).reshape(-1), label1, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = f1_score(np.array(train_y).reshape(-1), label1, average=None)\n",
    "print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('is_train_201907' + str(20) + '.txt')\n",
    "train = train.merge(attr, on='link', how='left')\n",
    "use_train_feats = [i for i in train.columns if i not in ['link', 'label', 'current_slice_id', 'future_slice_id', 'label_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "for clf in clfs:\n",
    "    test_pred = clf.predict(test[use_train_feats], num_iteration=clf.best_iteration)/len(clfs)\n",
    "    #print(test_pred.shape)\n",
    "    if(flag==0):\n",
    "        sum_result = test_pred[np.newaxis,:]\n",
    "    else:\n",
    "        sum_result = np.vstack((sum_result,test_pred[np.newaxis,:]))\n",
    "    flag = flag + 1\n",
    "    #print(sum_result.shape)\n",
    "    print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahhhhh = np.average(sum_result,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahhhhh*=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahhhhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahhhhh[:,0] *= 0.8\n",
    "ahhhhh[:,1] *= 0.8\n",
    "ahhhhh[:,2] *= 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahhhhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.argmax(ahhhhh,axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['label']]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[['link', 'current_slice_id', 'future_slice_id','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('Own1026.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

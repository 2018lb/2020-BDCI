{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_fit1(X_train, y_train):\n",
    "    categorical_features_indices = [ 0,  2,  3,  6, 15, 16, 19, 28, 29, 32, 41, 42, 45, 54, 55, 58, 67, 68, 71, 72, 73, 74, 75, 76, 78, 79]\n",
    "    model = CatBoostClassifier(iterations=300, depth=5,cat_features=categorical_features_indices,learning_rate=0.5, loss_function='Logloss',\n",
    "                            logging_level='Verbose')\n",
    "    model.fit(X_train,y_train,eval_set=(X_train, y_train))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train/is_train_20190701.txt')\n",
    "# train = pd.merge(train[['link','current_slice_id','future_slice_id']][(train.future_slice_id <= 50)],train,how='left') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('train/is_train_201907'+str(16)+'.txt')\n",
    "train = train.append(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = pd.read_csv('per_road_pro.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('is_train_data/is_train_20190723.txt')\n",
    "train = pd.merge(train, pro, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('pro_0',1)\n",
    "train = train.drop('pro_1',1)\n",
    "train = train.drop('pro_2',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = train.label\n",
    "train = train.drop('label',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    " \n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    " \n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_sample(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('current_speed_min',1)\n",
    "train = train.drop('current_eta_min',1)\n",
    "train = train.drop('current_cnt_min',1)\n",
    "train = train.drop('current_state_min',1)\n",
    "\n",
    "train = train.drop('his_28_speed_min',1)\n",
    "train = train.drop('his_28_eta_min',1)\n",
    "train = train.drop('his_28_cnt_min',1)\n",
    "train = train.drop('his_28_state_min',1)\n",
    "\n",
    "train = train.drop('his_21_speed_min',1)\n",
    "train = train.drop('his_21_eta_min',1)\n",
    "train = train.drop('his_21_cnt_min',1)\n",
    "train = train.drop('his_21_state_min',1)\n",
    "\n",
    "train = train.drop('his_14_speed_min',1)\n",
    "train = train.drop('his_14_eta_min',1)\n",
    "train = train.drop('his_14_cnt_min',1)\n",
    "train = train.drop('his_14_state_min',1)\n",
    "\n",
    "train = train.drop('his_7_speed_min',1)\n",
    "train = train.drop('his_7_eta_min',1)\n",
    "train = train.drop('his_7_cnt_min',1)\n",
    "train = train.drop('his_7_state_min',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('train//is_train_20190730.txt')\n",
    "y_5 = train_1.label\n",
    "train_1 = pd.merge(train_1, pro, how='left')\n",
    "train_1 = train_1.drop('label',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train,y,test_size=0.2 , random_state=1234)\n",
    "classweight = {0:0.4,1:0.4,2:0.2}\n",
    "\n",
    "model = CatBoostClassifier(iterations=200,depth=6,l2_leaf_reg=8,learning_rate=0.5,random_strength=1,\n",
    "                                      loss_function='MultiClassOneVsAll',logging_level='Verbose')\n",
    "\n",
    "model.fit(X_train,y_train,eval_set=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_validation, y_train, y_validation = train_test_split(train.loc[:,'time_diff':'width'],y,test_size=0.25 , random_state=1234)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train,y,test_size=0.2 , random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where(X_train.dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classweight = {0:0.4,1:0.4,2:0.2}\n",
    "model = CatBoostClassifier(iterations=200,depth=6,l2_leaf_reg=8,learning_rate=0.5,random_strength=1,\n",
    "                                      loss_function='MultiClassOneVsAll',logging_level='Verbose')\n",
    "\n",
    "model.fit(X_train,y_train,eval_set=(train_1,y_5),verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = np.array((y_train+1))\n",
    "# model.fit(X_train,y_train,eval_set=(X_validation,y_validation),sample_weight==w)\n",
    "model.fit(X_train,y_train,eval_set=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(classification_report(y_validation, model.predict(X_validation), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(classification_report(y_validation, model.predict(X_validation), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fea_ = model.feature_importances_\n",
    "fea_name = model.feature_names_\n",
    "plt.figure(figsize=(10, 50))\n",
    "plt.barh(fea_name,fea_,height =0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('train//is_train_20190730.txt')\n",
    "y_5 = train_1.label\n",
    "train_1 = pd.merge(train_1, pro, how='left')\n",
    "train_1 = train_1.drop('label',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('is_train_data/is_train_20190701.txt')\n",
    "train_1 = pd.merge(train_1[['link','current_slice_id','future_slice_id']][(train_1.future_slice_id <= 50)],train_1,how='left') \n",
    "for i in tqdm(range(25, 31)):\n",
    "    train1 = pd.read_csv('is_train_data/is_train_201907'+str(i)+'.txt')\n",
    "    train_1 = train_1.append(pd.merge(train1[['link','current_slice_id','future_slice_id']][(train1.future_slice_id <= 50)],train1,how='left'))\n",
    "\n",
    "train_1 = pd.merge(train_1, pro, how='left')\n",
    "y_5 = train_1.label\n",
    "train_1 = train_1.drop('label',1)\n",
    "train_1 = train_1.drop('is_high',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_1.drop('pro_0',1)\n",
    "train_1 = train_1.drop('pro_1',1)\n",
    "train_1 = train_1.drop('pro_2',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_1 = train_1.drop('current_speed_min',1)\n",
    "train_1 = train_1.drop('current_eta_min',1)\n",
    "train_1 = train_1.drop('current_cnt_min',1)\n",
    "train_1 = train_1.drop('current_state_min',1)\n",
    "\n",
    "train_1 = train_1.drop('his_28_speed_min',1)\n",
    "train_1 = train_1.drop('his_28_eta_min',1)\n",
    "train_1 = train_1.drop('his_28_cnt_min',1)\n",
    "train_1 = train_1.drop('his_28_state_min',1)\n",
    "\n",
    "train_1 = train_1.drop('his_21_speed_min',1)\n",
    "train_1 = train_1.drop('his_21_eta_min',1)\n",
    "train_1 = train_1.drop('his_21_cnt_min',1)\n",
    "train_1 = train_1.drop('his_21_state_min',1)\n",
    "\n",
    "train_1 = train_1.drop('his_14_speed_min',1)\n",
    "train_1 = train_1.drop('his_14_eta_min',1)\n",
    "train_1 = train_1.drop('his_14_cnt_min',1)\n",
    "train_1 = train_1.drop('his_14_state_min',1)\n",
    "\n",
    "train_1 = train_1.drop('his_7_speed_min',1)\n",
    "train_1 = train_1.drop('his_7_eta_min',1)\n",
    "train_1 = train_1.drop('his_7_cnt_min',1)\n",
    "train_1 = train_1.drop('his_7_state_min',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = model.predict(train_1)\n",
    "print(classification_report(y_5, kkk, digits=4))\n",
    "report = f1_score(y_5, kkk, average=None)\n",
    "print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kkk = model.predict(train_1)\n",
    "print(classification_report(y_5, kkk, digits=4))\n",
    "report = f1_score(y_5, kkk, average=None)\n",
    "print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 无high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = model.predict(train_1)\n",
    "print(classification_report(y_5, kkk, digits=4))\n",
    "report = f1_score(y_5, kkk, average=None)\n",
    "print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_5, model.predict(train_1), digits=4))\n",
    "report = f1_score(y_5, model.predict(train_1), average=None)\n",
    "print('Score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16号预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(classification_report(y_validation, model.predict(X_validation), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = []\n",
    "for i in range(504891):\n",
    "    s = k['linkid_' 'label_' 'current_slice_id_' 'future_slice_id'][i]\n",
    "    n = len(s)\n",
    "    k2 = 0\n",
    "    num2 = []\n",
    "    cnt = 0\n",
    "    for j in range(n):\n",
    "        if s[j] == ' ':\n",
    "            k2 += 1\n",
    "            if k2 != 2:\n",
    "                num2.append(cnt)\n",
    "            cnt = 0\n",
    "            continue\n",
    "        if s[j] == '-': continue\n",
    "        cnt = cnt * 10 + int(s[j])\n",
    "        if j == n - 1:\n",
    "            num2.append(cnt)\n",
    "    num2.append(3)\n",
    "    num.append(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num[504890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open(f'f.csv','w',encoding='utf-8',newline='')\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow([\"link\",\"current_slice_id\",\"future_slice_id\",\"label\"])\n",
    "csv_writer.writerows(num)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
